---
title: "Common Misconceptions in AI"
startDate: 2025-01-12T14:52:12.367Z
type: "thread"
topics: ["Artificial Intelligence", "Embodiment", "Anthropology"]
external:
  url: "https://harimus.github.io//2024/05/31/motortask.html"
  title: "Common Misconceptions About the Complexity in Robotics vs AI"
  author: "Dan Ogawa"
---

A roboticist breaks down common misconceptions about what's hard and easy in robotics. A response to
everyone asking “can't we just stick a large language model into its brain to make it more capable?”

Contrary to the assumptions of many people, making robots perceive and move in the world in the way
humans can turns out to be an extraordinarily hard problem to solve. While seemingly “hard” problems
like scoring well on intelligence tests, winning at chess, and acing the GMAT turn out to be much
easier.

Everyone thought it would be extremely hard and computationally expensive to teach computers
language, and easy to teach them to identify objects visually. The opposite turned out to be true.
This is known as [Moravec's Paradox](https://en.wikipedia.org/wiki/Moravec%27s_paradox).

Especially liked the ending where Dan explores _why_ people are so resistant to the idea picking up
a cup is more complex than solving logic puzzles. Partly anthropocentrism; humans are special
because we can do higher order thinking. Any lowly animal can sense the world and move through it.
Partly social class bias; people who work manual labour jobs using their bodies are less valued then
people who sit still using their intellect to solve problems.
