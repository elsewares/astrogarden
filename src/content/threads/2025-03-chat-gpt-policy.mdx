---
title: "ChatGPT Would be a Decent Policy Advisor"
startDate: 2025-03-13T16:30:58.501Z
type: "thread"
topics: ["Artificial Intelligence", "Language Models"]
external:
  url: "https://archive.is/i89l9#selection-1037.0-1049.44"
  title: "Revealed: How the UK tech secretary uses ChatGPT for policy advice"
  author: "Chris Stokel-Walker for the New Scientist"
---

The New Scientist used freedom of information laws to get the ChatGPT records of the UK's technology secretary.

The headline hints at a damning expos√©, but ends up being a story about a politician making pretty reasonable and sensible use of language models to be more informed and make better policy decisions.

He asked it why small business owners are slow to adopt AI, which popular podcasts he should appear on, and to define terms like _antimatter_ and _digital inclusion_.

This all seems extremely fine to me. Perhaps my standards for politicians are too low, but I assume they don't actually know much and rely heavily on advisors to define terms for them and decide on policy improvements. And I think ChatGPT connected to some grounded sources would be a decent policy advisor. Better than most human policy advisors. At least when it comes to consistency, rapidly searching and synthesising lots of documents, and avoiding personal bias. Models still carry the bias of their creators, but it all becomes a trade-off between human flaws and model flaws.

Claiming language models should have anything to do with national governance feels slightly insane. But we're also sitting in a moment where Trump and Musk are implementing policies that trigger trade wars and crash the U.S. economy. And I have to think "What if we just put Claude in charge?"

I joke. Kind of.
